{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
     ]
    }
   ],
   "source": [
    "from tasks.two_digit_addition_task.arithmetic import get_token_positions, get_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = get_task(hf=True,size=10000)\n",
    "print(\"Raw input:\")\n",
    "print(task.raw_all_data[\"input\"][0])\n",
    "task.display_counterfactual_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778e17f5593144a88312338b1e6ffea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:1\n",
      "INPUT: The sum of 57 and 78 is \n",
      "LABEL: 135\n",
      "PREDICTION: 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828a5dba3c3f4c85afe4d1195434cd68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLABEL:\u001b[39m\u001b[33m\"\u001b[39m, task.raw_all_data[\u001b[33m\"\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m])\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPREDICTION:\u001b[39m\u001b[33m\"\u001b[39m, pipeline.dump(pipeline.generate(task.raw_all_data[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m])))\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchecker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/CausalAbstraction/task.py:180\u001b[39m, in \u001b[36mTask.filter\u001b[39m\u001b[34m(self, pipeline, checker, batch_size, verbose)\u001b[39m\n\u001b[32m    178\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m orig_valid, cf_dumped, cf_dumped_flatten, cf_pred_flatten, cf_preds\n\u001b[32m    179\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m cf_expected, cf_valid\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m torch.cuda.empty_cache()\n\u001b[32m    182\u001b[39m gc.collect()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:984\u001b[39m, in \u001b[36msynchronize\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Wait for all kernels in all streams on a CUDA device to complete.\u001b[39;00m\n\u001b[32m    977\u001b[39m \n\u001b[32m    978\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    981\u001b[39m \u001b[33;03m        if :attr:`device` is ``None`` (default).\u001b[39;00m\n\u001b[32m    982\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    983\u001b[39m _lazy_init()\n\u001b[32m--> \u001b[39m\u001b[32m984\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    985\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/cuda/__init__.py:442\u001b[39m, in \u001b[36mdevice.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28mself\u001b[39m.prev_idx = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_exchange_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from pipeline import LMPipeline\n",
    "import torch\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "# model_name = \"Qwen/Qwen2.5-0.5B\"\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "\n",
    "if \"llama\" in model_name:\n",
    "    max_new_tokens = 1\n",
    "elif \"gemma\" in model_name:\n",
    "    max_new_tokens = 3\n",
    "\n",
    "def checker(output_text, expected):\n",
    "    if expected[0] == \"0\":\n",
    "        expected = expected[1:]\n",
    "        if max_new_tokens == 3:\n",
    "            return output_text[-3:-1] == expected\n",
    "    return expected == output_text\n",
    "\n",
    "\n",
    "pipeline = LMPipeline(model_name, max_new_tokens=max_new_tokens, device=device, dtype=torch.float16)\n",
    "pipeline.tokenizer.padding_side = \"left\"\n",
    "batch_size = 1024\n",
    "print(\"DEVICE:\", pipeline.model.device)\n",
    "\n",
    "print(\"INPUT:\", task.raw_all_data[\"input\"][0])\n",
    "print(\"LABEL:\", task.raw_all_data[\"label\"][0])\n",
    "print(\"PREDICTION:\", pipeline.dump(pipeline.generate(task.raw_all_data[\"input\"][0])))\n",
    "\n",
    "task.filter(pipeline, checker, verbose=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of 73 and 49 is \n",
      "<bos>The sum of 73 and 4**9** is \n",
      "<bos>The sum of 73 and 49 is** **\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token_positions = get_token_positions(pipeline, task)\n",
    "input = task.sample_raw_input()\n",
    "print(input)\n",
    "for token_position in token_positions:\n",
    "    print(token_position.highlight_selected_token(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "start = 0\n",
    "end = pipeline.get_num_layers()\n",
    "config={\"batch_size\":256 , \"evaluation_batch_size\": batch_size, \"training_epoch\":1, \"n_features\":16, \"regularization_coefficient\":0.0, \"output_scores\":False}\n",
    "names = [\"random\", \"ones_carry\"]\n",
    "train_data = [name + \"_train\" for name in names]\n",
    "validation_data = [name + \"_validation\" for name in names]\n",
    "test_data = [name + \"_test\" for name in names]\n",
    "test_data += [name + \"_testprivate\" for name in names]\n",
    "verbose = True\n",
    "results_dir = \"math_results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:0,Token:op2_last)']\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:0,Token:last)']\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:1,Token:op2_last)']\n",
      "Intervention key: layer_1_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:1,Token:last)']\n",
      "Intervention key: layer_1_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:2,Token:op2_last)']\n",
      "Intervention key: layer_2_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:2,Token:last)']\n",
      "Intervention key: layer_2_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:3,Token:op2_last)']\n",
      "Intervention key: layer_3_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:3,Token:last)']\n",
      "Intervention key: layer_3_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:4,Token:op2_last)']\n",
      "Intervention key: layer_4_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:4,Token:last)']\n",
      "Intervention key: layer_4_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:5,Token:op2_last)']\n",
      "Intervention key: layer_5_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:5,Token:last)']\n",
      "Intervention key: layer_5_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:6,Token:op2_last)']\n",
      "Intervention key: layer_6_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:6,Token:last)']\n",
      "Intervention key: layer_6_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:7,Token:op2_last)']\n",
      "Intervention key: layer_7_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:7,Token:last)']\n",
      "Intervention key: layer_7_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:8,Token:op2_last)']\n",
      "Intervention key: layer_8_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:8,Token:last)']\n",
      "Intervention key: layer_8_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:9,Token:op2_last)']\n",
      "Intervention key: layer_9_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:9,Token:last)']\n",
      "Intervention key: layer_9_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:10,Token:op2_last)']\n",
      "Intervention key: layer_10_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:10,Token:last)']\n",
      "Intervention key: layer_10_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:11,Token:op2_last)']\n",
      "Intervention key: layer_11_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:11,Token:last)']\n",
      "Intervention key: layer_11_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:12,Token:op2_last)']\n",
      "Intervention key: layer_12_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:12,Token:last)']\n",
      "Intervention key: layer_12_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:13,Token:op2_last)']\n",
      "Intervention key: layer_13_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:13,Token:last)']\n",
      "Intervention key: layer_13_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:14,Token:op2_last)']\n",
      "Intervention key: layer_14_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:14,Token:last)']\n",
      "Intervention key: layer_14_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:15,Token:op2_last)']\n",
      "Intervention key: layer_15_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:15,Token:last)']\n",
      "Intervention key: layer_15_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:16,Token:op2_last)']\n",
      "Intervention key: layer_16_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:16,Token:last)']\n",
      "Intervention key: layer_16_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:17,Token:op2_last)']\n",
      "Intervention key: layer_17_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:17,Token:last)']\n",
      "Intervention key: layer_17_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:18,Token:op2_last)']\n",
      "Intervention key: layer_18_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:18,Token:last)']\n",
      "Intervention key: layer_18_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:19,Token:op2_last)']\n",
      "Intervention key: layer_19_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:19,Token:last)']\n",
      "Intervention key: layer_19_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:20,Token:op2_last)']\n",
      "Intervention key: layer_20_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:20,Token:last)']\n",
      "Intervention key: layer_20_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:21,Token:op2_last)']\n",
      "Intervention key: layer_21_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:21,Token:last)']\n",
      "Intervention key: layer_21_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:22,Token:op2_last)']\n",
      "Intervention key: layer_22_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:22,Token:last)']\n",
      "Intervention key: layer_22_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:23,Token:op2_last)']\n",
      "Intervention key: layer_23_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:23,Token:last)']\n",
      "Intervention key: layer_23_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:24,Token:op2_last)']\n",
      "Intervention key: layer_24_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:24,Token:last)']\n",
      "Intervention key: layer_24_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:25,Token:op2_last)']\n",
      "Intervention key: layer_25_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for random_test with model units [id='ResidualStream(Layer:25,Token:last)']\n",
      "Intervention key: layer_25_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:40<00:00,  8.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:0,Token:op2_last)']\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:0,Token:last)']\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:1,Token:op2_last)']\n",
      "Intervention key: layer_1_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:1,Token:last)']\n",
      "Intervention key: layer_1_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:2,Token:op2_last)']\n",
      "Intervention key: layer_2_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:2,Token:last)']\n",
      "Intervention key: layer_2_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:3,Token:op2_last)']\n",
      "Intervention key: layer_3_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:3,Token:last)']\n",
      "Intervention key: layer_3_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:4,Token:op2_last)']\n",
      "Intervention key: layer_4_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 5/5 [00:41<00:00,  8.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for ones_carry_test with model units [id='ResidualStream(Layer:4,Token:last)']\n",
      "Intervention key: layer_4_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches:  80%|████████  | 4/5 [00:35<00:08,  8.90s/it]"
     ]
    }
   ],
   "source": [
    "from experiments.aggregate_experiments import residual_stream_baselines\n",
    "residual_stream_baselines(pipeline=pipeline, task=task, token_positions=token_positions, train_data=train_data, test_data=test_data, config=config, target_variables=[\"ones_carry\"], checker=checker, start=start, end=end, verbose=verbose, results_dir=results_dir, \n",
    "                          methods=[\"DBM+SAE\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
