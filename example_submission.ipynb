{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223fa7696bf24629a74c32e1c44e434c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b38e2d76f0c347dd9aa4473d4cd8267c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3464dd4d676244bf91b0128ca74651f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/110 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383ce19320c549f9af05093664fc01a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0222cd2e4f8d49ce9d7e557b2e81894c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4cc597d6de451690c37d578b66a8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c68103dc0d4d7984dde07ece4f173e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26239bc4d5854b978910f85eb7277c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4928d55be0ed426281331b86ba63d2b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7c9ad3d780f4979995f1b5279566929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36759b67f757441ca2b03a9f4280d3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05811934efe348368a6c30f0a8bf5226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b57ec49d1bce484c9ab8e550e514aba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n",
      "INPUT: Question: The coconuts is brown. What color is the coconuts?\n",
      "A. red\n",
      "B. orange\n",
      "C. brown\n",
      "D. purple\n",
      "Answer:\n",
      "LABEL:  C\n",
      "PREDICTION:  C\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a62cde2eb441cf98d78adf68efd4bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39c3c868773e40f2aafee4faffa69b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17703906c8914ae592c18430c1a806fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f541216fabae40e89b643b6b95c2d860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c54cc71f9b4dea962ba123e63a1504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1127753072c4ea7b753f2cb5caca924",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51ef7cceff1486abbcde0456075a254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9230cf4963544a28a6377330015f1209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723bd45ac0ca48af911f311d718eb514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24f8d0230db6449c9a1e370258ca5c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78760436738041a6a5bab57340d52baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b23a34b9dcd420885d9fb492b5d88d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: The diapers is white. What color is the diapers?\n",
      "A. purple\n",
      "B. white\n",
      "C. pink\n",
      "D. blue\n",
      "Answer:\n",
      "<bos>Question: The diapers is white. What color is the diapers?\n",
      "A. purple\n",
      "**B**. white\n",
      "C. pink\n",
      "D. blue\n",
      "Answer:\n",
      "<bos>Question: The diapers is white. What color is the diapers?\n",
      "A. purple\n",
      "B. white\n",
      "C. pink\n",
      "D. blue\n",
      "Answer**:**\n"
     ]
    }
   ],
   "source": [
    "from tasks.simple_MCQA.simple_MCQA import get_task, get_token_positions \n",
    "import gc\n",
    "import torch\n",
    "from pipeline import LMPipeline\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "task = get_task(hf=True, size=None)\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def clear_memory():\n",
    "    # Clear Python garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear CUDA cache if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    # Force a synchronization point to ensure memory is freed\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "def checker(output_text, expected):\n",
    "    return expected in output_text\n",
    "\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "pipeline = LMPipeline(model_name, max_new_tokens=1, device=device, dtype=torch.float16)\n",
    "pipeline.tokenizer.padding_side = \"left\"\n",
    "batch_size = 32\n",
    "print(\"DEVICE:\", pipeline.model.device)\n",
    "\n",
    "print(\"INPUT:\", task.raw_all_data[\"input\"][0])\n",
    "print(\"LABEL:\", task.raw_all_data[\"label\"][0])\n",
    "print(\"PREDICTION:\", pipeline.dump(pipeline.generate(task.raw_all_data[\"input\"][0])))\n",
    "\n",
    "task.filter(pipeline, checker, verbose=False, batch_size=batch_size)\n",
    "\n",
    "token_positions = get_token_positions(pipeline, task)\n",
    "\n",
    "input = task.sample_raw_input()\n",
    "print(input)\n",
    "for token_position in token_positions:\n",
    "    print(token_position.highlight_selected_token(input))\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "start = 0 \n",
    "end = 1\n",
    "\n",
    "# Use original config for all models\n",
    "config = {\"batch_size\": 64, \"training_epoch\": 1, \"n_features\": 16, \"regularization_coefficient\": 0.0}\n",
    "    \n",
    "names = [\"answerPosition\", \"randomLetter\", \"answerPosition_randomLetter\"]\n",
    "train_data = [name + \"_train\" for name in names]\n",
    "validation_data = [name + \"_validation\" for name in names]\n",
    "test_data = [name + \"_test\" for name in names]\n",
    "# test_data += [name + \"_testprivate\" for name in names]\n",
    "verbose = False \n",
    "results_dir = \"mock_submission_results\"\n",
    "model_dir = \"mock_submission_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.LM_experiments import PatchResidualStream\n",
    "import os\n",
    "\n",
    "def heatmaps(experiment, results, config, results_dir):\n",
    "    heatmap_path = os.path.join(results_dir, \"heatmaps\", config[\"method_name\"], \n",
    "                        pipeline.model.__class__.__name__, \"-\".join(target_variables))\n",
    "\n",
    "    # Create directory if it doesn't exist\n",
    "    if not os.path.exists(heatmap_path):\n",
    "        os.makedirs(heatmap_path)\n",
    "    experiment.plot_heatmaps(results, save_path=heatmap_path)\n",
    "    experiment.plot_heatmaps(results, average_counterfactuals=True, save_path=heatmap_path)\n",
    "\n",
    "target_variables=[\"answer_pointer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:03<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    }
   ],
   "source": [
    "config[\"method_name\"] = \"DAS\"\n",
    "experiment = PatchResidualStream(pipeline, task, list(range(start,end)), token_positions, checker, config=config)\n",
    "experiment.train_interventions(train_data, target_variables, method=\"DAS\", verbose=verbose, model_dir=os.path.join(model_dir, config[\"method_name\"]))\n",
    "raw_results = experiment.perform_interventions(test_data, verbose=verbose)\n",
    "processed_results = experiment.interpret_results(raw_results, target_variables, save_dir=results_dir)\n",
    "heatmaps(experiment, processed_results, config, results_dir)\n",
    "\n",
    "# # Release memory before next experiment\n",
    "del experiment, raw_results, processed_results\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]/home/atticus/Documents/GitHub/CausalAbstraction/model_units/model_units.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_sigmoid = torch.sigmoid(self.mask / torch.tensor(self.temperature))\n",
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    }
   ],
   "source": [
    "config[\"method_name\"] = \"DBM+SAE\"\n",
    "from sae_lens import SAE\n",
    "\n",
    "\n",
    "def sae_loader(layer):\n",
    "    sae, _, _ = SAE.from_pretrained(\n",
    "        release = \"gemma-scope-2b-pt-res-canonical\",\n",
    "        sae_id = f\"layer_{layer}/width_16k/canonical\",\n",
    "        device = \"cpu\",\n",
    "    )\n",
    "    return sae\n",
    "\n",
    "experiment = PatchResidualStream(pipeline, task, list(range(start,end)), token_positions, checker, config=config)\n",
    "experiment.build_SAE_feature_intervention(sae_loader)\n",
    "experiment.train_interventions(train_data, target_variables, method=\"DBM\", verbose=verbose, model_dir=os.path.join(model_dir, config[\"method_name\"]))\n",
    "raw_results = experiment.perform_interventions(test_data, verbose=verbose)\n",
    "processed_results = experiment.interpret_results(raw_results, target_variables, save_dir=results_dir)\n",
    "heatmaps(experiment, processed_results, config, results_dir)\n",
    "\n",
    "# Final memory cleanup\n",
    "del experiment, raw_results, processed_results, sae_loader\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]/home/atticus/Documents/GitHub/CausalAbstraction/model_units/model_units.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask_sigmoid = torch.sigmoid(self.mask / torch.tensor(self.temperature))\n",
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    }
   ],
   "source": [
    "config[\"method_name\"] = \"DBM\"\n",
    "experiment = PatchResidualStream(pipeline, task, list(range(start,end)), token_positions, checker, config=config)\n",
    "experiment.train_interventions(train_data, target_variables, method=\"DBM\", verbose=verbose, model_dir=os.path.join(model_dir, config[\"method_name\"]))\n",
    "raw_results = experiment.perform_interventions(test_data, verbose=verbose)\n",
    "processed_results = experiment.interpret_results(raw_results, target_variables, save_dir=results_dir)\n",
    "heatmaps(experiment, processed_results, config, results_dir)\n",
    "\n",
    "del experiment, raw_results, processed_results\n",
    "clear_memory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "[1, 2, 5, 7, 8, 12, 14, 15, 16, 19, 25, 26, 27, 29, 30, 32, 33, 34, 35, 36, 37, 39, 40, 41, 42, 44, 45, 48, 49, 50, 51, 54, 55, 57, 58, 61, 63, 65, 68, 69, 70, 73, 74, 75, 76, 80, 81, 82, 83, 85, 86, 88, 89, 93, 94, 96, 98, 99, 100, 104, 105, 110, 112, 113, 116, 118, 119, 121, 122, 123, 124, 125, 127, 128, 131, 132, 133, 135, 138, 139, 140, 142, 143, 144, 146, 148, 149, 150, 151, 154, 155, 156, 157, 160, 161, 162, 163, 165, 166, 167, 169, 170, 175, 176, 177, 178, 180, 183, 184, 185, 188, 189, 190, 191, 193, 194, 196, 197, 198, 199, 201, 202, 203, 204, 206, 209, 213, 215, 216, 217, 221, 222, 223, 224, 227, 232, 235, 237, 238, 242, 243, 244, 248, 249, 252, 255, 263, 264, 265, 266, 268, 269, 270, 273, 275, 278, 279, 280, 281, 282, 283, 284, 286, 289, 290, 292, 294, 295, 296, 297, 299, 302, 304, 306, 308, 309, 310, 311, 313, 314, 315, 319, 321, 322, 323, 325, 326, 327, 332, 338, 339, 340, 342, 345, 348, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 364, 365, 366, 367, 368, 369, 370, 372, 373, 374, 376, 379, 382, 385, 386, 387, 390, 392, 393, 394, 399, 402, 403, 404, 405, 408, 409, 410, 411, 413, 415, 418, 420, 424, 425, 426, 430, 432, 433, 434, 439, 440, 444, 445, 447, 448, 449, 450, 452, 453, 455, 456, 457, 459, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 472, 473, 475, 476, 479, 481, 484, 488, 491, 495, 497, 498, 499, 502, 503, 504, 506, 507, 508, 510, 511, 512, 514, 515, 518, 522, 523, 525, 527, 529, 530, 532, 533, 535, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 548, 549, 550, 553, 555, 556, 560, 561, 563, 564, 565, 568, 569, 572, 574, 577, 578, 583, 584, 585, 586, 587, 588, 589, 590, 592, 593, 596, 599, 600, 601, 602, 603, 604, 607, 608, 611, 612, 614, 615, 619, 620, 622, 623, 625, 626, 628, 631, 638, 639, 642, 643, 645, 646, 647, 650, 651, 652, 653, 654, 656, 658, 663, 665, 666, 667, 668, 671, 673, 675, 677, 680, 682, 683, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 698, 699, 700, 701, 705, 708, 709, 710, 711, 712, 713, 714, 716, 717, 720, 722, 723, 724, 726, 727, 731, 733, 734, 737, 738, 742, 743, 744, 745, 747, 749, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 768, 769, 770, 771, 773, 774, 776, 780, 781, 783, 784, 785, 786, 787, 788, 791, 792, 794, 796, 800, 804, 805, 806, 810, 812, 813, 814, 817, 818, 820, 821, 824, 825, 830, 831, 836, 837, 838, 839, 840, 843, 846, 848, 849, 850, 852, 853, 854, 855, 857, 859, 860, 861, 864, 865, 867, 869, 872, 876, 877, 878, 879, 881, 882, 883, 884, 886, 887, 888, 899, 902, 903, 904, 905, 906, 907, 910, 911, 914, 915, 918, 919, 920, 922, 923, 924, 925, 926, 927, 930, 931, 932, 933, 934, 936, 938, 940, 942, 944, 946, 950, 951, 953, 955, 956, 957, 959, 960, 964, 966, 967, 968, 972, 973, 974, 975, 981, 982, 985, 986, 987, 989, 990, 991, 993, 995, 996, 1003, 1005, 1006, 1007, 1008, 1011, 1013, 1015, 1016, 1017, 1018, 1020, 1022, 1023, 1025, 1026, 1028, 1029, 1032, 1033, 1035, 1036, 1038, 1039, 1040, 1044, 1045, 1047, 1048, 1049, 1050, 1052, 1055, 1056, 1057, 1062, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1074, 1075, 1076, 1077, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1089, 1090, 1094, 1096, 1098, 1100, 1101, 1104, 1106, 1107, 1108, 1110, 1115, 1116, 1117, 1118, 1119, 1120, 1122, 1124, 1125, 1126, 1128, 1129, 1131, 1133, 1137, 1138, 1139, 1140, 1141, 1142, 1145, 1147, 1148, 1149, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1163, 1168, 1169, 1170, 1173, 1174, 1176, 1178, 1179, 1182, 1183, 1187, 1190, 1191, 1193, 1194, 1196, 1197, 1198, 1200, 1202, 1205, 1206, 1207, 1211, 1212, 1214, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1233, 1236, 1237, 1238, 1239, 1241, 1242, 1245, 1246, 1249, 1250, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1265, 1266, 1272, 1275, 1276, 1277, 1278, 1279, 1284, 1285, 1286, 1290, 1292, 1295, 1298, 1299, 1301, 1306, 1309, 1312, 1315, 1316, 1327, 1329, 1330, 1331, 1332, 1334, 1335, 1337, 1338, 1339, 1341, 1342, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1359, 1363, 1364, 1365, 1366, 1367, 1368, 1370, 1373, 1374, 1375, 1376, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1398, 1400, 1402, 1404, 1407, 1408, 1409, 1410, 1415, 1416, 1417, 1420, 1422, 1423, 1424, 1425, 1426, 1428, 1430, 1431, 1432, 1433, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1445, 1446, 1447, 1448, 1451, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1463, 1464, 1466, 1467, 1468, 1470, 1471, 1472, 1475, 1476, 1477, 1478, 1480, 1483, 1484, 1486, 1489, 1490, 1491, 1492, 1494, 1495, 1497, 1499, 1500, 1501, 1502, 1504, 1505, 1508, 1510, 1511, 1514, 1515, 1516, 1518, 1519, 1520, 1521, 1522, 1523, 1525, 1526, 1527, 1528, 1529, 1531, 1534, 1536, 1537, 1540, 1541, 1542, 1549, 1550, 1551, 1552, 1554, 1555, 1556, 1557, 1558, 1560, 1561, 1566, 1567, 1568, 1570, 1571, 1572, 1574, 1576, 1578, 1579, 1582, 1585, 1587, 1590, 1591, 1592, 1593, 1594, 1596, 1597, 1598, 1602, 1603, 1606, 1607, 1609, 1610, 1611, 1614, 1615, 1616, 1618, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1632, 1634, 1638, 1642, 1645, 1647, 1648, 1650, 1651, 1653, 1654, 1657, 1660, 1661, 1664, 1667, 1670, 1671, 1672, 1673, 1674, 1676, 1679, 1681, 1682, 1685, 1686, 1687, 1688, 1689, 1691, 1693, 1694, 1695, 1697, 1700, 1702, 1703, 1704, 1706, 1707, 1708, 1709, 1710, 1711, 1713, 1715, 1717, 1721, 1722, 1723, 1725, 1727, 1731, 1735, 1737, 1741, 1744, 1745, 1746, 1747, 1751, 1753, 1755, 1756, 1758, 1760, 1761, 1762, 1763, 1764, 1765, 1767, 1768, 1770, 1772, 1773, 1774, 1776, 1777, 1778, 1779, 1780, 1782, 1783, 1784, 1785, 1787, 1788, 1789, 1790, 1793, 1794, 1795, 1798, 1800, 1801, 1802, 1804, 1807, 1808, 1810, 1811, 1812, 1813, 1814, 1816, 1817, 1818, 1819, 1823, 1825, 1827, 1830, 1831, 1833, 1834, 1835, 1836, 1838, 1839, 1842, 1843, 1845, 1846, 1847, 1851, 1852, 1853, 1854, 1855, 1858, 1862, 1863, 1864, 1865, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1904, 1906, 1907, 1910, 1912, 1914, 1915, 1918, 1920, 1924, 1929, 1930, 1931, 1936, 1937, 1938, 1941, 1942, 1943, 1944, 1945, 1946, 1948, 1949, 1950, 1951, 1952, 1953, 1954, 1955, 1957, 1964, 1967, 1968, 1969, 1970, 1972, 1974, 1976, 1979, 1980, 1982, 1988, 1989, 1990, 1992, 1994, 1998, 1999, 2003, 2004, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2015, 2017, 2018, 2019, 2022, 2024, 2027, 2028, 2031, 2032, 2033, 2034, 2035, 2036, 2037, 2038, 2039, 2040, 2042, 2047, 2049, 2050, 2054, 2055, 2056, 2058, 2062, 2063, 2064, 2067, 2068, 2069, 2070, 2073, 2075, 2076, 2078, 2082, 2084, 2085, 2086, 2088, 2089, 2090, 2091, 2092, 2093, 2095, 2100, 2102, 2103, 2104, 2105, 2106, 2108, 2109, 2110, 2111, 2112, 2113, 2114, 2116, 2117, 2119, 2120, 2128, 2130, 2131, 2133, 2134, 2135, 2136, 2137, 2139, 2141, 2142, 2143, 2145, 2146, 2147, 2148, 2149, 2150, 2151, 2152, 2153, 2154, 2158, 2160, 2162, 2164, 2165, 2166, 2169, 2170, 2171, 2172, 2174, 2176, 2177, 2178, 2179, 2180, 2181, 2183, 2184, 2185, 2187, 2189, 2194, 2196, 2197, 2198, 2200, 2202, 2203, 2204, 2206, 2208, 2209, 2210, 2211, 2213, 2215, 2216, 2217, 2219, 2220, 2221, 2223, 2226, 2228, 2236, 2237, 2238, 2239, 2240, 2241, 2242, 2244, 2245, 2247, 2249, 2250, 2251, 2252, 2253, 2255, 2256, 2257, 2258, 2259, 2260, 2261, 2262, 2264, 2265, 2266, 2269, 2270, 2271, 2272, 2273, 2274, 2275, 2276, 2278, 2280, 2281, 2283, 2285, 2287, 2288, 2290, 2291, 2292, 2293, 2295, 2296, 2299, 2300, 2301, 2303]\n",
      "[1, 4, 5, 8, 9, 10, 11, 12, 16, 21, 22, 23, 24, 25, 28, 29, 30, 32, 33, 35, 37, 38, 39, 40, 41, 45, 48, 49, 50, 51, 52, 55, 56, 59, 61, 62, 63, 66, 68, 70, 74, 75, 76, 78, 80, 81, 82, 84, 85, 89, 93, 94, 95, 96, 97, 98, 105, 109, 114, 115, 120, 122, 128, 130, 134, 135, 137, 138, 139, 140, 143, 144, 150, 151, 157, 159, 160, 162, 163, 164, 166, 167, 169, 171, 179, 181, 182, 185, 187, 190, 192, 193, 197, 199, 200, 206, 208, 209, 210, 212, 213, 215, 217, 219, 221, 223, 227, 228, 231, 232, 233, 234, 236, 237, 238, 240, 241, 242, 252, 253, 254, 255, 256, 257, 258, 259, 261, 262, 264, 265, 266, 267, 268, 270, 271, 272, 273, 274, 275, 276, 280, 283, 284, 285, 286, 289, 290, 292, 293, 295, 296, 298, 299, 301, 304, 306, 308, 312, 313, 316, 320, 323, 326, 327, 328, 332, 334, 336, 337, 338, 340, 342, 343, 344, 345, 346, 347, 349, 350, 354, 359, 361, 364, 365, 370, 371, 372, 373, 376, 377, 378, 379, 380, 383, 384, 389, 390, 391, 393, 401, 403, 404, 407, 408, 411, 412, 414, 415, 420, 423, 424, 425, 426, 427, 429, 431, 432, 433, 439, 441, 443, 444, 448, 449, 450, 453, 454, 455, 458, 462, 465, 466, 468, 469, 474, 475, 476, 477, 481, 482, 483, 486, 487, 488, 489, 490, 492, 494, 496, 500, 502, 503, 504, 505, 506, 509, 511, 512, 513, 515, 516, 517, 519, 522, 523, 526, 528, 529, 531, 534, 538, 544, 545, 546, 549, 552, 553, 557, 558, 559, 562, 564, 565, 566, 569, 573, 574, 577, 581, 584, 585, 586, 588, 589, 590, 593, 594, 600, 601, 602, 604, 605, 607, 609, 611, 612, 614, 617, 618, 619, 620, 621, 623, 624, 626, 628, 630, 634, 635, 642, 643, 645, 649, 650, 651, 652, 653, 654, 655, 656, 659, 663, 665, 666, 667, 668, 670, 671, 672, 673, 676, 683, 685, 686, 688, 689, 691, 693, 696, 697, 698, 699, 700, 701, 702, 707, 708, 709, 711, 718, 720, 721, 722, 723, 724, 725, 726, 729, 730, 731, 733, 737, 739, 742, 743, 746, 747, 749, 752, 753, 754, 756, 762, 763, 764, 765, 766, 767, 768, 769, 770, 775, 777, 778, 781, 782, 784, 786, 787, 788, 789, 791, 799, 802, 804, 806, 808, 810, 814, 817, 820, 821, 825, 826, 830, 834, 835, 836, 838, 842, 845, 846, 852, 854, 855, 856, 857, 858, 859, 860, 861, 864, 865, 868, 869, 870, 872, 874, 875, 883, 884, 885, 886, 887, 888, 891, 894, 896, 898, 900, 902, 903, 904, 906, 915, 918, 921, 924, 925, 926, 928, 930, 934, 937, 940, 941, 942, 943, 945, 946, 948, 949, 950, 952, 953, 954, 955, 957, 958, 960, 962, 963, 964, 965, 967, 969, 971, 972, 973, 975, 976, 977, 981, 984, 985, 986, 987, 988, 993, 994, 999, 1000, 1002, 1005, 1008, 1012, 1013, 1014, 1016, 1017, 1018, 1019, 1023, 1024, 1027, 1028, 1029, 1031, 1032, 1033, 1034, 1035, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1052, 1054, 1056, 1057, 1059, 1060, 1062, 1066, 1069, 1071, 1072, 1073, 1075, 1076, 1077, 1083, 1085, 1086, 1088, 1092, 1094, 1097, 1098, 1099, 1100, 1103, 1104, 1106, 1108, 1109, 1111, 1113, 1115, 1117, 1118, 1119, 1120, 1122, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1133, 1134, 1135, 1136, 1138, 1140, 1141, 1142, 1143, 1147, 1148, 1151, 1152, 1153, 1154, 1155, 1159, 1160, 1162, 1164, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1177, 1178, 1181, 1182, 1184, 1185, 1187, 1189, 1191, 1192, 1194, 1195, 1197, 1201, 1202, 1203, 1204, 1205, 1208, 1209, 1210, 1211, 1212, 1213, 1217, 1218, 1220, 1221, 1222, 1226, 1228, 1229, 1231, 1232, 1235, 1236, 1237, 1240, 1241, 1243, 1244, 1247, 1249, 1253, 1254, 1255, 1256, 1260, 1261, 1262, 1264, 1265, 1266, 1270, 1272, 1273, 1274, 1275, 1277, 1281, 1282, 1283, 1287, 1288, 1289, 1292, 1294, 1298, 1299, 1301, 1302, 1303, 1304, 1305, 1306, 1308, 1311, 1313, 1315, 1318, 1319, 1323, 1325, 1327, 1330, 1333, 1335, 1336, 1338, 1340, 1343, 1344, 1346, 1347, 1348, 1349, 1353, 1356, 1357, 1360, 1364, 1365, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1381, 1384, 1385, 1386, 1387, 1388, 1390, 1393, 1395, 1396, 1397, 1399, 1402, 1406, 1407, 1408, 1409, 1410, 1415, 1416, 1418, 1422, 1423, 1427, 1428, 1429, 1431, 1433, 1434, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1452, 1456, 1458, 1460, 1461, 1463, 1464, 1466, 1467, 1468, 1469, 1470, 1475, 1476, 1478, 1479, 1480, 1481, 1485, 1488, 1490, 1491, 1497, 1499, 1500, 1501, 1504, 1505, 1506, 1513, 1514, 1516, 1517, 1518, 1519, 1520, 1522, 1523, 1527, 1528, 1529, 1530, 1531, 1532, 1534, 1544, 1547, 1548, 1549, 1551, 1554, 1555, 1556, 1558, 1561, 1562, 1563, 1566, 1569, 1570, 1573, 1575, 1576, 1578, 1582, 1583, 1587, 1588, 1589, 1591, 1592, 1593, 1597, 1599, 1601, 1602, 1606, 1607, 1608, 1611, 1615, 1620, 1621, 1625, 1626, 1627, 1628, 1632, 1633, 1636, 1637, 1639, 1640, 1641, 1642, 1643, 1645, 1646, 1652, 1653, 1657, 1660, 1661, 1662, 1664, 1665, 1666, 1667, 1668, 1669, 1673, 1674, 1675, 1677, 1678, 1679, 1680, 1682, 1684, 1685, 1686, 1687, 1691, 1692, 1696, 1698, 1703, 1707, 1710, 1711, 1712, 1713, 1715, 1720, 1721, 1724, 1725, 1726, 1727, 1731, 1733, 1736, 1737, 1738, 1740, 1741, 1742, 1743, 1745, 1748, 1749, 1750, 1753, 1756, 1757, 1758, 1760, 1761, 1762, 1763, 1765, 1769, 1770, 1771, 1772, 1774, 1779, 1780, 1781, 1783, 1787, 1788, 1790, 1791, 1794, 1795, 1796, 1798, 1800, 1805, 1807, 1808, 1809, 1810, 1811, 1812, 1814, 1815, 1818, 1819, 1820, 1824, 1825, 1828, 1829, 1832, 1833, 1834, 1835, 1837, 1838, 1839, 1841, 1844, 1847, 1850, 1851, 1856, 1857, 1859, 1862, 1863, 1866, 1867, 1868, 1871, 1874, 1877, 1878, 1885, 1887, 1889, 1891, 1892, 1893, 1895, 1897, 1898, 1899, 1900, 1903, 1906, 1908, 1911, 1912, 1913, 1914, 1916, 1919, 1920, 1924, 1928, 1929, 1939, 1940, 1941, 1942, 1943, 1944, 1950, 1953, 1955, 1957, 1958, 1960, 1964, 1965, 1966, 1967, 1968, 1971, 1973, 1974, 1975, 1977, 1982, 1984, 1985, 1990, 1991, 1992, 1993, 1995, 1996, 1997, 1998, 2000, 2002, 2004, 2013, 2014, 2015, 2017, 2019, 2021, 2024, 2027, 2028, 2029, 2032, 2034, 2040, 2042, 2043, 2046, 2047, 2048, 2049, 2050, 2051, 2054, 2057, 2060, 2061, 2064, 2066, 2067, 2069, 2071, 2072, 2074, 2077, 2079, 2081, 2082, 2083, 2086, 2087, 2088, 2089, 2090, 2091, 2092, 2093, 2095, 2096, 2097, 2098, 2099, 2100, 2107, 2108, 2109, 2111, 2112, 2114, 2115, 2116, 2117, 2118, 2121, 2123, 2124, 2125, 2126, 2128, 2129, 2130, 2132, 2133, 2135, 2136, 2137, 2139, 2140, 2142, 2143, 2144, 2146, 2147, 2152, 2156, 2157, 2158, 2159, 2161, 2162, 2165, 2166, 2167, 2168, 2170, 2171, 2172, 2174, 2176, 2177, 2179, 2180, 2181, 2182, 2184, 2185, 2186, 2187, 2188, 2190, 2194, 2196, 2198, 2200, 2209, 2214, 2216, 2217, 2219, 2221, 2223, 2224, 2225, 2226, 2229, 2232, 2233, 2234, 2235, 2236, 2238, 2242, 2244, 2247, 2249, 2251, 2252, 2256, 2257, 2259, 2262, 2264, 2265, 2268, 2269, 2270, 2271, 2273, 2276, 2282, 2283, 2284, 2285, 2289, 2291, 2294, 2299, 2300, 2303]\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "[38, 48, 201, 204, 233, 301, 350, 360, 374, 386, 438, 465, 518, 555, 575, 578, 581, 625, 668, 693, 701, 717, 765, 788, 843, 895, 995, 1013, 1028, 1076, 1120, 1129, 1164, 1197, 1240, 1279, 1288, 1291, 1311, 1315, 1317, 1319, 1322, 1380, 1454, 1473, 1476, 1491, 1550, 1568, 1585, 1691, 1723, 2027, 2034, 2038, 2045, 2080, 2170, 2209, 2263, 2282, 2389, 2407, 2414, 2440, 2441, 2525, 2534, 2558, 2564, 2717, 2741, 2747, 2760, 2826, 2846, 2851, 2862, 2939, 2945, 2977, 2981, 3201, 3204, 3338, 3391, 3422, 3445, 3519, 3527, 3530, 3572, 3593, 3614, 3615, 3669, 3684, 3701, 3708, 3775, 3778, 3810, 3812, 3832, 3893, 3914, 3931, 4015, 4017, 4047, 4111, 4145, 4180, 4210, 4228, 4292, 4360, 4409, 4420, 4514, 4570, 4620, 4621, 4676, 4678, 4679, 4787, 4830, 4982, 5020, 5048, 5105, 5157, 5158, 5188, 5196, 5218, 5279, 5311, 5406, 5412, 5420, 5439, 5523, 5580, 5589, 5609, 5639, 5846, 5896, 5900, 5903, 5908, 5962, 5976, 6032, 6114, 6153, 6224, 6231, 6272, 6349, 6355, 6362, 6426, 6470, 6485, 6493, 6545, 6633, 6645, 6706, 6754, 6855, 6856, 6915, 6931, 6938, 6950, 6971, 7000, 7016, 7020, 7045, 7074, 7100, 7114, 7125, 7130, 7174, 7183, 7184, 7228, 7275, 7276, 7297, 7334, 7427, 7463, 7499, 7539, 7563, 7609, 7644, 7669, 7675, 7684, 7708, 7801, 7927, 7959, 7988, 8030, 8119, 8166, 8266, 8275, 8335, 8349, 8350, 8396, 8416, 8527, 8563, 8585, 8586, 8609, 8635, 8645, 8648, 8696, 8741, 8902, 8925, 8977, 9190, 9216, 9266, 9309, 9340, 9368, 9378, 9430, 9466, 9515, 9585, 9586, 9603, 9621, 9655, 9660, 9675, 9767, 9795, 9836, 9882, 9901, 9911, 9913, 9928, 9948, 9966, 10001, 10021, 10050, 10071, 10121, 10123, 10170, 10212, 10243, 10399, 10412, 10431, 10443, 10470, 10528, 10545, 10696, 10807, 10820, 10876, 10884, 10980, 11001, 11033, 11082, 11130, 11153, 11154, 11175, 11188, 11213, 11246, 11273, 11295, 11370, 11375, 11464, 11500, 11515, 11765, 11788, 11793, 11794, 11803, 11825, 11880, 11919, 11943, 11946, 11952, 12058, 12065, 12152, 12186, 12203, 12286, 12298, 12312, 12398, 12478, 12539, 12588, 12623, 12625, 12632, 12637, 12677, 12735, 12764, 12787, 12793, 12826, 12895, 12940, 12950, 13004, 13059, 13089, 13119, 13269, 13287, 13321, 13329, 13331, 13365, 13387, 13418, 13434, 13452, 13460, 13484, 13565, 13748, 13761, 13800, 13841, 13842, 13919, 13937, 13944, 13967, 13990, 14084, 14103, 14127, 14133, 14152, 14192, 14239, 14276, 14278, 14321, 14330, 14397, 14467, 14478, 14561, 14572, 14583, 14692, 14723, 14856, 14920, 14952, 14963, 14994, 14998, 15080, 15126, 15129, 15130, 15212, 15219, 15306, 15324, 15348, 15410, 15417, 15495, 15514, 15521, 15540, 15728, 15741, 15751, 15799, 15841, 15859, 15876, 15900, 15914, 15928, 15951, 16038, 16049, 16064, 16145, 16180, 16206, 16224, 16297, 16301, 16315, 16334, 16345]\n",
      "[1381, 4492, 6645, 8447, 8714, 10415, 10548, 11217, 12430, 14681, 15526, 15906]\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    }
   ],
   "source": [
    "for method in [\"DAS\", \"DBM\", \"DBM+SAE\"]:\n",
    "    config[\"method_name\"] = method\n",
    "    experiment = PatchResidualStream(pipeline, task, list(range(start,end)), token_positions, checker, config=config)\n",
    "    if method == \"DBM+SAE\":\n",
    "        def sae_loader(layer):\n",
    "            sae, _, _ = SAE.from_pretrained(\n",
    "                release = \"gemma-scope-2b-pt-res-canonical\",\n",
    "                sae_id = f\"layer_{layer}/width_16k/canonical\",\n",
    "                device = \"cpu\",\n",
    "            )\n",
    "            return sae\n",
    "        experiment.build_SAE_feature_intervention(sae_loader)\n",
    "    experiment.load_featurizers(os.path.join(model_dir, method))\n",
    "    raw_results = experiment.perform_interventions(test_data, verbose=verbose)\n",
    "    processed_results = experiment.interpret_results(raw_results, target_variables, save_dir=results_dir + \"_loaded\")\n",
    "    heatmaps(experiment, processed_results, config, results_dir + \"_loaded\")\n",
    "    del experiment, raw_results, processed_results\n",
    "    clear_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
