import sys, os, json, random, re
from pathlib import Path
sys.path.append(str(Path(__file__).resolve().parent.parent))
sys.path.append(str(Path(__file__).resolve().parent.parent.parent))

from CausalAbstraction.causal.causal_model import CausalModel
from CausalAbstraction.neural.LM_units import TokenPosition, get_last_token_index


# Get the current file's directory
current_dir = os.path.dirname(os.path.abspath(__file__))

# Get the parent directory of the parent directory (grandparent)
grandparent_dir = os.path.dirname(os.path.dirname(current_dir))

# Add the grandparent directory to the path
sys.path.append(grandparent_dir)

from copy import deepcopy
from tasks.hf_dataloader import load_hf_dataset


# Load RAVEL metadata - only keep the essential city entity data
_RAVEL_DATA_DIR = os.path.dirname(os.path.abspath(__file__))
_CITY_ENTITY = {}


def load_city_entity_data():
    """Load city entity data if not already loaded."""
    if not _CITY_ENTITY:
        city_data_path = os.path.join(_RAVEL_DATA_DIR, 'ravel_city_entity.json')
        if os.path.exists(city_data_path):
            _CITY_ENTITY.update(json.load(open(city_data_path)))
        else:
            # If file doesn't exist, create a minimal set for testing
            _CITY_ENTITY.update({
                "Paris": {"Continent": "Europe", "Country": "France", "Language": "French"},
                "Tokyo": {"Continent": "Asia", "Country": "Japan", "Language": "Japanese"},
                "New York": {"Continent": "North America", "Country": "United States", "Language": "English"},
                # Add more as needed
            })


def get_causal_model():
    """
    Create and return the causal model for RAVEL task.
    """
    # Ensure city data is loaded
    load_city_entity_data()
    
    # Define variables
    attributes = ["Continent", "Country", "Language"]
    variables = ["raw_input", "entity", "queried_attribute", "answer", "raw_output"] + attributes
   
    # Define parent relationships
    parents = {
        "raw_input": ["entity", "queried_attribute"],  # raw_input depends on entity and attribute
        "entity": [],
        "queried_attribute": [],
        "answer": ["entity", "queried_attribute", "Continent", "Country", "Language"],
        "Continent": ["entity"],
        "Country": ["entity"], 
        "Language": ["entity"],
        "raw_output": ["answer"]  # raw_output depends on answer
    }
    
    # Define possible values for each variable
    values = {
        "raw_input": [""],  # Placeholder, generated by mechanism
        "entity": list(_CITY_ENTITY.keys()), 
        "queried_attribute": attributes + ["wikipedia"],  # Include wikipedia as a possible query
        "answer": [""],  # Will be populated with all possible answers
        "Continent": list(set(city["Continent"] for city in _CITY_ENTITY.values())),
        "Country": list(set(city["Country"] for city in _CITY_ENTITY.values())),
        "Language": list(set(city["Language"] for city in _CITY_ENTITY.values())),
        "raw_output": [""]  # Placeholder, generated by mechanism
    }
    
    # Collect all possible answers
    all_answers = set()
    for city_data in _CITY_ENTITY.values():
        all_answers.update(city_data.values())
    all_answers.add("")  # For wikipedia queries
    values["answer"] = list(all_answers)

    # Define mechanisms
    def get_raw_input(entity, queried_attribute):
        """Generate the input prompt based on entity and attribute."""
        if queried_attribute == "wikipedia":
            return f"Q: What is {entity}? A:"
        else:
            return f"Q: What is the {queried_attribute.lower()} of {entity}? A:"
    
    def get_entity():
        """Randomly select an entity."""
        return random.choice(list(_CITY_ENTITY.keys()))
    
    def get_queried_attribute():
        """Randomly select an attribute to query."""
        return random.choice(attributes + ["wikipedia"])
    
    def get_answer(entity, q_attr, *attr_values):
        """Get the answer based on entity and queried attribute."""
        if q_attr == "wikipedia":
            return ""  # Empty answer for wikipedia queries
        idx = attributes.index(q_attr)
        return attr_values[idx]
    
    def get_continent(entity):
        """Get continent for the entity."""
        return _CITY_ENTITY[entity]["Continent"]
    
    def get_country(entity):
        """Get country for the entity."""
        return _CITY_ENTITY[entity]["Country"]
    
    def get_language(entity):
        """Get language for the entity."""
        return _CITY_ENTITY[entity]["Language"]
    
    def get_raw_output(answer):
        """Format the output."""
        return f" {answer}" if answer else ""

    mechanisms = {
        "raw_input": get_raw_input,
        "entity": get_entity,
        "queried_attribute": get_queried_attribute,
        "answer": get_answer,
        "Continent": get_continent,
        "Country": get_country,
        "Language": get_language,
        "raw_output": get_raw_output
    }
    
    return CausalModel(variables, values, parents, mechanisms, id="RAVEL")


def get_counterfactual_datasets(hf=True, size=None, load_private_data=False):
    """
    Load and return counterfactual datasets for RAVEL task.
    """
    # Ensure city data is loaded
    load_city_entity_data()
    
    if hf:
        # Load dataset from HuggingFace with customized parsing
        datasets = {}
        for split in ["train", "val", "test"]:
            temp = load_hf_dataset(
                dataset_path="mib-bench/ravel",
                split=split,
                parse_fn=parse_ravel_example,
                size=size,
                shuffle=True
            )
            datasets.update(temp)
            
        # Load private test set
        if load_private_data:
            private = load_hf_dataset(
                dataset_path="mib-bench/ravel_private_test",
                split="test",
                parse_fn=parse_ravel_example,
                size=size,
                shuffle=True
            )
            datasets.update({k+"private": v for k, v in private.items()})
        
        return datasets
    
    # Non-HF implementation would go here if needed
    return {}


def get_token_positions(pipeline, causal_model):
    """
    Get token positions for RAVEL task interventions.
    """
    def get_entity_last_token_position(input_dict, pipeline):
        """
        Find the last token position of the entity in the prompt.
        
        Args:
            input_dict: Dictionary containing the input data
            pipeline: LMPipeline for tokenization
            
        Returns:
            List containing the token index of the last entity token
        """
        # Get the prompt and entity
        if isinstance(input_dict, dict):
            prompt = input_dict.get("raw_input", "")
            # Run causal model to get the entity
            setting = causal_model.run_forward(input_dict)
            entity = setting["entity"]
        else:
            # Fallback if input is just a string
            prompt = input_dict
            # Try to extract entity from the prompt
            entity = None
            for city in _CITY_ENTITY.keys():
                if city in prompt:
                    entity = city
                    break
        
        if not entity:
            raise ValueError(f"Could not find entity in prompt: {prompt}")
        
        # Find the entity in the prompt
        entity_match = re.search(r'\b' + re.escape(entity) + r'\b', prompt)
        if not entity_match:
            raise ValueError(f"Entity '{entity}' not found in prompt: {prompt}")
        
        # Get the substring up to the end of the entity
        substring = prompt[:entity_match.end()]
        
        # Tokenize the substring
        tokens = pipeline.load(substring)["input_ids"][0]
        
        # The last token of the entity is at the end of the tokenized substring
        return [len(tokens) - 1]
    
    # Create TokenPosition objects
    token_positions = [
        TokenPosition(lambda x: get_last_token_index(x, pipeline), pipeline, id="last_token"),
        TokenPosition(lambda x: get_entity_last_token_position(x, pipeline), pipeline, id="entity_last_token")
    ]
    
    return token_positions


def parse_ravel_example(row):
    """
    Convert a single dataset row into a dict for the RAVEL causal model.
    
    Args:
        row: A row from the RAVEL dataset
        
    Returns:
        Dict containing the parsed variables
    """
    # Extract the basic information
    entity = row.get("entity", "")
    attribute = row.get("attribute", "")
    prompt = row.get("prompt", "")
    
    # Create the variables dictionary
    variables_dict = {
        "entity": entity,
        "queried_attribute": attribute,
    }
    
    # If we have a prompt, we can use it as raw_input
    if prompt:
        variables_dict["raw_input"] = prompt
    
    return variables_dict