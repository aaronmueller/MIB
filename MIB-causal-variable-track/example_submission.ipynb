{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the dataset since mib-bench/copycolors_mcqa_private_test couldn't be found on the Hugging Face Hub\n",
      "Found the latest cached dataset configuration '4_answer_choices' at /home/atticus/.cache/huggingface/datasets/mib-bench___copycolors_mcqa_private_test/4_answer_choices/0.0.0/da600e08a8c9fe40917ac887eda693de57b9f04d (last modified on Tue Jun  3 19:36:15 2025).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: dict_keys(['answerPosition_train', 'randomLetter_train', 'answerPosition_randomLetter_train', 'answerPosition_validation', 'randomLetter_validation', 'answerPosition_randomLetter_validation', 'answerPosition_test', 'randomLetter_test', 'answerPosition_randomLetter_test', 'answerPosition_testprivate', 'randomLetter_testprivate', 'answerPosition_randomLetter_testprivate'])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a64addeda948ee81b4334d0704dfbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda:0\n",
      "INPUT: {'choice0': 'red', 'choice1': 'orange', 'choice2': 'brown', 'choice3': 'purple', 'question': ['brown', 'question: coconuts'], 'raw_input': 'Question: Coconuts are brown. What color are coconuts?\\nA. red\\nB. orange\\nC. brown\\nD. purple\\nAnswer:', 'symbol0': 'A', 'symbol1': 'B', 'symbol2': 'C', 'symbol3': 'D'}\n",
      "EXPECTED OUTPUT:  C\n",
      "MODEL PREDICTION:  C\n",
      "\n",
      "Filtering datasets based on model performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_train: 100%|██████████| 1/1 [00:01<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_train': kept 106/110 examples (96.4%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering randomLetter_train: 100%|██████████| 1/1 [00:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'randomLetter_train': kept 75/110 examples (68.2%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_randomLetter_train: 100%|██████████| 1/1 [00:01<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_randomLetter_train': kept 70/110 examples (63.6%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_validation: 100%|██████████| 1/1 [00:00<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_validation': kept 50/50 examples (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering randomLetter_validation: 100%|██████████| 1/1 [00:00<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'randomLetter_validation': kept 37/50 examples (74.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_randomLetter_validation: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_randomLetter_validation': kept 35/50 examples (70.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_test: 100%|██████████| 1/1 [00:00<00:00,  1.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_test': kept 50/50 examples (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering randomLetter_test: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'randomLetter_test': kept 34/50 examples (68.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_randomLetter_test: 100%|██████████| 1/1 [00:00<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_randomLetter_test': kept 38/50 examples (76.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_testprivate: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_testprivate': kept 50/50 examples (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering randomLetter_testprivate: 100%|██████████| 1/1 [00:00<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'randomLetter_testprivate': kept 34/50 examples (68.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering answerPosition_randomLetter_testprivate: 100%|██████████| 1/1 [00:00<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'answerPosition_randomLetter_testprivate': kept 33/50 examples (66.0%)\n",
      "\n",
      "Total filtering results:\n",
      "Original examples: 780\n",
      "Kept examples: 612\n",
      "Overall keep rate: 78.5%\n",
      "\n",
      "Token positions highlighted in samples:\n",
      "<bos>Question: Coconuts are brown. What color are coconuts?\n",
      "A. red\n",
      "B. orange\n",
      "C. purple\n",
      "**D**. brown\n",
      "Answer:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve().parent.parent))\n",
    "\n",
    "from tasks.simple_MCQA.simple_MCQA import get_token_positions, get_counterfactual_datasets, get_causal_model\n",
    "from experiments.aggregate_experiments import residual_stream_baselines\n",
    "from neural.pipeline import LMPipeline\n",
    "from experiments.filter_experiment import FilterExperiment\n",
    "import gc\n",
    "import torch\n",
    "import os\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Get counterfactual datasets and causal model\n",
    "counterfactual_datasets = get_counterfactual_datasets(hf=True, size=None)\n",
    "causal_model = get_causal_model()\n",
    "\n",
    "# Print available datasets\n",
    "print(\"Available datasets:\", counterfactual_datasets.keys())\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def clear_memory():\n",
    "    # Clear Python garbage collector\n",
    "    gc.collect()\n",
    "    \n",
    "    # Clear CUDA cache if available\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    # Force a synchronization point to ensure memory is freed\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "\n",
    "def checker(output_text, expected):\n",
    "    return expected in output_text\n",
    "\n",
    "model_name = \"google/gemma-2-2b\"\n",
    "pipeline = LMPipeline(model_name, max_new_tokens=1, device=device, dtype=torch.float16)\n",
    "pipeline.tokenizer.padding_side = \"left\"\n",
    "batch_size = 32\n",
    "print(\"DEVICE:\", pipeline.model.device)\n",
    "\n",
    "# Get a sample input and check model's prediction\n",
    "sampled_example = next(iter(counterfactual_datasets.values()))[0]\n",
    "print(\"INPUT:\", sampled_example[\"input\"])\n",
    "print(\"EXPECTED OUTPUT:\", causal_model.run_forward(sampled_example[\"input\"])[\"raw_output\"])\n",
    "print(\"MODEL PREDICTION:\", pipeline.dump(pipeline.generate(sampled_example[\"input\"])))\n",
    "\n",
    "# Filter the datasets based on model performance\n",
    "print(\"\\nFiltering datasets based on model performance...\")\n",
    "exp = FilterExperiment(pipeline, causal_model, checker)\n",
    "filtered_datasets = exp.filter(counterfactual_datasets, verbose=True, batch_size=1024)\n",
    "\n",
    "token_positions = get_token_positions(pipeline, causal_model)\n",
    "\n",
    "# Display token highlighting for a sample\n",
    "print(\"\\nToken positions highlighted in samples:\")\n",
    "for dataset in filtered_datasets.values():\n",
    "    for token_position in token_positions:\n",
    "        example = dataset[0]\n",
    "        print(token_position.highlight_selected_token(example[\"counterfactual_inputs\"][0]))\n",
    "        break\n",
    "    break\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "start = 0 \n",
    "end = 1\n",
    "\n",
    "# Use original config for all models\n",
    "config = {\"batch_size\": 64, \"evaluation_batch_size\": 1024, \"training_epoch\": 1, \"n_features\": 16, \"regularization_coefficient\": 0.0, \"output_scores\": False}\n",
    "    \n",
    "names = [\"answerPosition\", \"randomLetter\", \"answerPosition_randomLetter\"]\n",
    "\n",
    "# Prepare train and test data dictionaries\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for name in names:\n",
    "    if name + \"_train\" in filtered_datasets:\n",
    "        train_data[name + \"_train\"] = filtered_datasets[name + \"_train\"]\n",
    "    if name + \"_test\" in filtered_datasets:\n",
    "        test_data[name + \"_test\"] = filtered_datasets[name + \"_test\"]\n",
    "    # Uncomment the line below if testprivate datasets are available\n",
    "    # if name + \"_testprivate\" in filtered_datasets:\n",
    "    #     test_data[name + \"_testprivate\"] = filtered_datasets[name + \"_testprivate\"]\n",
    "\n",
    "verbose = False \n",
    "results_dir = \"mock_submission_results\"\n",
    "model_dir = os.path.join(\"mock_submission\", \"4_answer_MCQA_Gemma2ForCausalLM_answer_pointer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "target_variables=[\"answer_pointer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DAS method...\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 4/4 [00:03<00:00,  1.14it/s, loss=1.82, accuracy=0.41, token_accuracy=0.41]\n",
      "Epoch: 100%|██████████| 1/1 [00:03<00:00,  3.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 4/4 [00:03<00:00,  1.32it/s, loss=2.19, accuracy=0.34, token_accuracy=0.34]\n",
      "Epoch: 100%|██████████| 1/1 [00:03<00:00,  3.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 4/4 [00:02<00:00,  1.41it/s, loss=2.2, accuracy=0.25, token_accuracy=0.25] \n",
      "Epoch: 100%|██████████| 1/1 [00:02<00:00,  2.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n"
     ]
    }
   ],
   "source": [
    "# Run DAS method (Direct Attribution with Subspace)\n",
    "print(\"Running DAS method...\")\n",
    "\n",
    "residual_stream_baselines(\n",
    "    pipeline=pipeline,\n",
    "    task=causal_model,\n",
    "    token_positions=token_positions,\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    config=config,\n",
    "    target_variables=target_variables,\n",
    "    checker=checker,\n",
    "    start=start,\n",
    "    end=end,\n",
    "    verbose=verbose,\n",
    "    model_dir=model_dir,\n",
    "    results_dir=results_dir,\n",
    "    methods=[\"DAS\"]  # Only run DAS method\n",
    ")\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Run DBM+SAE method (uncomment to use)\n",
    "# NOTE: This method requires the sae_lens library and is specific to certain models\n",
    "\n",
    "# print(\"Running DBM+SAE method...\")\n",
    "\n",
    "# residual_stream_baselines(\n",
    "#     pipeline=pipeline,\n",
    "#     task=causal_model,\n",
    "#     token_positions=token_positions,\n",
    "#     train_data=train_data,\n",
    "#     test_data=test_data,\n",
    "#     config=config,\n",
    "#     target_variables=target_variables,\n",
    "#     checker=checker,\n",
    "#     start=start,\n",
    "#     end=end,\n",
    "#     verbose=verbose,\n",
    "#     model_dir=model_dir,\n",
    "#     results_dir=results_dir,\n",
    "#     methods=[\"DBM+SAE\"]  # Only run DBM+SAE method\n",
    "# )\n",
    "\n",
    "# clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Run DBM method (uncomment to use)\n",
    "# print(\"Running DBM method...\")\n",
    "\n",
    "# residual_stream_baselines(\n",
    "#     pipeline=pipeline,\n",
    "#     task=causal_model,\n",
    "#     token_positions=token_positions,\n",
    "#     train_data=train_data,\n",
    "#     test_data=test_data,\n",
    "#     config=config,\n",
    "#     target_variables=target_variables,\n",
    "#     checker=checker,\n",
    "#     start=start,\n",
    "#     end=end,\n",
    "#     verbose=verbose,\n",
    "#     model_dir=model_dir,\n",
    "#     results_dir=results_dir,\n",
    "#     methods=[\"DBM\"]  # Only run DBM method\n",
    "# )\n",
    "\n",
    "# clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained models and running inference...\n",
      "Testing DAS method...\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Intervention key: layer_0_comp_block_output_unit_pos_nunit_1#0\n",
      "Inference completed!\n"
     ]
    }
   ],
   "source": [
    "# Example: Load saved models and run inference\n",
    "# This demonstrates how to load previously trained featurizers and run interventions\n",
    "\n",
    "from experiments.residual_stream_experiment import PatchResidualStream\n",
    "\n",
    "print(\"Loading trained models and running inference...\")\n",
    "\n",
    "for method in [\"DAS\"]:  # Can also test \"DBM\", \"DBM+SAE\", etc.\n",
    "    print(f\"Testing {method} method...\")\n",
    "    \n",
    "    # Create experiment with same configuration\n",
    "    config[\"method_name\"] = method\n",
    "    experiment = PatchResidualStream(pipeline, causal_model, list(range(start,end)), token_positions, checker, config=config)\n",
    "    \n",
    "    # Set up SAE loader if needed for DBM+SAE method\n",
    "    if method == \"DBM+SAE\":\n",
    "        from sae_lens import SAE\n",
    "        def sae_loader(layer):\n",
    "            sae, _, _ = SAE.from_pretrained(\n",
    "                release = \"gemma-scope-2b-pt-res-canonical\",\n",
    "                sae_id = f\"layer_{layer}/width_16k/canonical\",\n",
    "                device = \"cpu\",\n",
    "            )\n",
    "            return sae\n",
    "        experiment.build_SAE_feature_intervention(sae_loader)\n",
    "    \n",
    "    # Load the trained featurizers\n",
    "    method_model_dir = os.path.join(model_dir, method) if method != \"DAS\" else model_dir\n",
    "    experiment.load_featurizers(method_model_dir)\n",
    "    \n",
    "    # Run interventions on test data\n",
    "    raw_results = experiment.perform_interventions(test_data, verbose=verbose, target_variables_list=[target_variables], save_dir=results_dir + \"_loaded\")\n",
    "    \n",
    "    # Clean up\n",
    "    del experiment, raw_results\n",
    "    clear_memory()\n",
    "\n",
    "print(\"Inference completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
