{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOI Example Submission - DAS Training for Attention Heads\n",
    "\n",
    "This notebook demonstrates how to train DAS (Direct Attribution with Subspace) on attention heads for the IOI (Indirect Object Identification) task using a Gemma model.\n",
    "\n",
    "## Overview\n",
    "1. Load IOI datasets and setup the model\n",
    "2. Learn linear parameters from training data\n",
    "3. Train DAS featurizers on selected attention heads\n",
    "4. Save trained models in submission format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nnsight is not detected. Please install via 'pip install nnsight' for nnsight backend.\n",
      "Using device: cuda:1\n",
      "Model: gemma\n",
      "Heads to train: [(7, 6), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path().resolve()))\n",
    "\n",
    "from tasks.IOI_task.ioi_task import get_causal_model, get_counterfactual_datasets, get_token_positions\n",
    "from CausalAbstraction.experiments.attention_head_experiment import PatchAttentionHeads\n",
    "from CausalAbstraction.experiments.filter_experiment import FilterExperiment\n",
    "from CausalAbstraction.experiments.aggregate_experiments import attention_head_baselines\n",
    "from baselines.ioi_baselines.ioi_utils import (\n",
    "    log_diff, clear_memory, checker, filter_checker, custom_loss, \n",
    "    ioi_loss_and_metric_fn, setup_pipeline\n",
    ")\n",
    "import torch\n",
    "import gc\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Clear memory before starting\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Set device\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Model configuration\n",
    "model_name = \"gemma\"  # Will use google/gemma-2-2b\n",
    "heads_list = [(7, 6), (8,1)]  \n",
    "\n",
    "print(f\"Model: {model_name}\")\n",
    "print(f\"Heads to train: {heads_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data and Setup Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets: dict_keys(['s1_io_flip_train', 's2_io_flip_train', 's1_ioi_flip_s2_ioi_flip_train', 's1_io_flip_test', 's2_io_flip_test', 's1_ioi_flip_s2_ioi_flip_test', 'same_train', 'same_test'])\n",
      "\n",
      "Sample input:\n",
      "  Raw input: As Carl and Maria left the consulate, Carl gave a fridge to\n",
      "  Name A: Carl\n",
      "  Name B: Maria\n",
      "  Name C: Carl\n"
     ]
    }
   ],
   "source": [
    "# Get counterfactual datasets with placeholder causal model\n",
    "# We'll update the causal model with learned parameters later\n",
    "causal_model = get_causal_model({\"bias\": 0.0, \"token_coeff\": 0.0, \"position_coeff\": 0.0})\n",
    "counterfactual_datasets = get_counterfactual_datasets(hf=True, size=10)#None)\n",
    "\n",
    "print(\"Available datasets:\", counterfactual_datasets.keys())\n",
    "\n",
    "# Get a sample to display\n",
    "sample_dataset = next(iter(counterfactual_datasets.values()))\n",
    "if len(sample_dataset) > 0:\n",
    "    sample = sample_dataset[0]\n",
    "    print(\"\\nSample input:\")\n",
    "    print(f\"  Raw input: {sample['input']['raw_input']}\")\n",
    "    print(f\"  Name A: {sample['input']['name_A']}\")\n",
    "    print(f\"  Name B: {sample['input']['name_B']}\")\n",
    "    print(f\"  Name C: {sample['input']['name_C']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6759c87f724e188e4800e52564f655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have set `use_cache` to `False`, but cache_implementation is set to hybrid. cache_implementation will have no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline device: cuda:1\n",
      "Model: Gemma2ForCausalLM\n",
      "Hidden size: 2304\n",
      "Number of layers: 26\n",
      "\n",
      "Testing model on sample:\n",
      "INPUT: As Carl and Maria left the consulate, Carl gave a fridge to\n",
      "EXPECTED OUTPUT: Maria\n",
      "MODEL PREDICTION:  Maria\n"
     ]
    }
   ],
   "source": [
    "# Set up pipeline\n",
    "pipeline, default_batch_size = setup_pipeline(model_name, device, eval_batch_size=None)\n",
    "batch_size = 32  # You can adjust this based on your GPU memory\n",
    "eval_batch_size = 64\n",
    "\n",
    "print(f\"Pipeline device: {pipeline.model.device}\")\n",
    "print(f\"Model: {pipeline.model.__class__.__name__}\")\n",
    "print(f\"Hidden size: {pipeline.model.config.hidden_size}\")\n",
    "print(f\"Number of layers: {pipeline.get_num_layers()}\")\n",
    "\n",
    "# Test model on a sample\n",
    "if len(sample_dataset) > 0:\n",
    "    sample = sample_dataset[0]\n",
    "    print(\"\\nTesting model on sample:\")\n",
    "    print(f\"INPUT: {sample['input']['raw_input']}\")\n",
    "    expected = causal_model.run_forward(sample['input'])['raw_output']\n",
    "    print(f\"EXPECTED OUTPUT: {expected}\")\n",
    "    print(f\"MODEL PREDICTION: {pipeline.dump(pipeline.generate(sample['input']['raw_input']))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Filter Datasets Based on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering datasets based on model performance...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering s1_io_flip_train: 100%|██████████| 1/1 [00:00<00:00,  1.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 's1_io_flip_train': kept 10/10 examples (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering s2_io_flip_train: 100%|██████████| 1/1 [00:00<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 's2_io_flip_train': kept 10/10 examples (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering s1_ioi_flip_s2_ioi_flip_train: 100%|██████████| 1/1 [00:00<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 's1_ioi_flip_s2_ioi_flip_train': kept 10/10 examples (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering s1_io_flip_test: 100%|██████████| 1/1 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 's1_io_flip_test': kept 6/10 examples (60.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering s2_io_flip_test: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 's2_io_flip_test': kept 7/10 examples (70.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering s1_ioi_flip_s2_ioi_flip_test: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 's1_ioi_flip_s2_ioi_flip_test': kept 7/10 examples (70.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering same_train: 100%|██████████| 1/1 [00:00<00:00,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'same_train': kept 10/10 examples (100.0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filtering same_test: 100%|██████████| 1/1 [00:00<00:00,  2.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'same_test': kept 7/10 examples (70.0%)\n",
      "\n",
      "Total filtering results:\n",
      "Original examples: 80\n",
      "Kept examples: 67\n",
      "Overall keep rate: 83.8%\n",
      "\n",
      "Token positions: ['all']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter the datasets\n",
    "print(\"Filtering datasets based on model performance...\")\n",
    "exp = FilterExperiment(pipeline, causal_model, filter_checker)\n",
    "filtered_datasets = exp.filter(counterfactual_datasets, verbose=True, batch_size=eval_batch_size)\n",
    "\n",
    "# Get token positions\n",
    "token_positions = get_token_positions(pipeline, causal_model)\n",
    "print(f\"\\nToken positions: {[pos.id for pos in token_positions]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Learn Linear Parameters from Training Data\n",
    "\n",
    "IOI requires linear parameters (bias, token_coeff, position_coeff) for the causal mechanism. We'll learn these from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading linear parameters from: baselines/ioi_linear_params.json\n",
      "Using coefficients for gemma:\n",
      "  bias: 11.7509765625\n",
      "  token_coeff: 0.0\n",
      "  position_coeff: -0.04589843749999991\n"
     ]
    }
   ],
   "source": [
    "# Load linear parameters from external file\n",
    "linear_params_file = \"baselines/ioi_linear_params.json\"\n",
    "\n",
    "print(f\"Loading linear parameters from: {linear_params_file}\")\n",
    "try:\n",
    "    if os.path.isfile(linear_params_file):\n",
    "        with open(linear_params_file, 'r') as f:\n",
    "            all_coeffs = json.load(f)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Linear parameters file not found: {linear_params_file}\")\n",
    "except Exception as e:\n",
    "    raise ValueError(f\"Failed to load linear_params: {e}\")\n",
    "\n",
    "# Find the coefficients for this model\n",
    "if model_name in all_coeffs:\n",
    "    coeffs = all_coeffs[model_name]\n",
    "elif \"default\" in all_coeffs:\n",
    "    coeffs = all_coeffs[\"default\"]\n",
    "else:\n",
    "    # Use the first available coefficients\n",
    "    coeffs = next(iter(all_coeffs.values()))\n",
    "\n",
    "# Validate required keys\n",
    "required_keys = ['bias', 'token_coeff', 'position_coeff']\n",
    "for key in required_keys:\n",
    "    if key not in coeffs:\n",
    "        raise ValueError(f\"Missing required key '{key}' in linear_coeffs for model {model_name}\")\n",
    "\n",
    "intercept = coeffs['bias']\n",
    "token_coef = coeffs['token_coeff']\n",
    "position_coef = coeffs['position_coeff']\n",
    "\n",
    "print(f\"Using coefficients for {model_name}:\")\n",
    "print(f\"  bias: {intercept}\")\n",
    "print(f\"  token_coeff: {token_coef}\")\n",
    "print(f\"  position_coeff: {position_coef}\")\n",
    "\n",
    "# Store parameters\n",
    "linear_params = {\n",
    "    \"bias\": float(intercept),\n",
    "    \"token_coeff\": float(token_coef),\n",
    "    \"position_coeff\": float(position_coef)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Update Causal Model with Learned Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Causal model updated with learned parameters\n"
     ]
    }
   ],
   "source": [
    "# Update the causal model with learned parameters\n",
    "causal_model = get_causal_model(linear_params)\n",
    "print(\"Causal model updated with learned parameters\")\n",
    "\n",
    "# Clear memory before training\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Prepare Training and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train datasets: ['s1_io_flip_train', 's2_io_flip_train', 's1_ioi_flip_s2_ioi_flip_train']\n",
      "Test datasets: ['s1_io_flip_test', 's2_io_flip_test', 's1_ioi_flip_s2_ioi_flip_test']\n"
     ]
    }
   ],
   "source": [
    "# Setup counterfactual names for IOI\n",
    "counterfactuals = [\"s1_io_flip\", \"s2_io_flip\", \"s1_ioi_flip_s2_ioi_flip\"]\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for counterfactual in counterfactuals:\n",
    "    if counterfactual + \"_train\" in filtered_datasets:\n",
    "        train_data[counterfactual + \"_train\"] = filtered_datasets[counterfactual + \"_train\"]\n",
    "    if counterfactual + \"_test\" in filtered_datasets:\n",
    "        test_data[counterfactual + \"_test\"] = filtered_datasets[counterfactual + \"_test\"]\n",
    "    # Note: We're not using private test data in this example\n",
    "\n",
    "print(\"Train datasets:\", list(train_data.keys()))\n",
    "print(\"Test datasets:\", list(test_data.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Configure Experiment Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: ioi_submission_results\n",
      "Models will be saved to: ioi_submission\n"
     ]
    }
   ],
   "source": [
    "# Setup experiment configuration for DAS\n",
    "config = {\n",
    "    \"evaluation_batch_size\": eval_batch_size,\n",
    "    \"batch_size\": batch_size, \n",
    "    \"training_epoch\": 2,  # Number of training epochs\n",
    "    \"check_raw\": True,\n",
    "    \"n_features\": 32,  # Feature dimension for DAS\n",
    "    \"regularization_coefficient\": 0.0, \n",
    "    \"output_scores\": True, \n",
    "    \"shuffle\": True, \n",
    "    \"temperature_schedule\": (1.0, 0.01),  # Temperature annealing for training\n",
    "    \"init_lr\": 1.0,\n",
    "    \"loss_and_metric_fn\": lambda pipeline, intervenable_model, batch, model_units_list: \n",
    "        ioi_loss_and_metric_fn(pipeline, intervenable_model, batch, model_units_list),\n",
    "}\n",
    "\n",
    "# Setup directories for saving results\n",
    "results_dir = \"ioi_submission_results\"\n",
    "model_dir = \"ioi_submission\"\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "if not os.path.exists(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "print(f\"Results will be saved to: {results_dir}\")\n",
    "print(f\"Models will be saved to: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Train DAS on Output Position Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training DAS for output_position variable...\n",
      "============================================================\n",
      "Running DAS method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 1/1 [00:00<00:00,  2.74it/s, loss=9.23, mse=9.23, rmse=3.04]\n",
      "Epoch: 1: 100%|██████████| 1/1 [00:00<00:00,  3.32it/s, loss=9.42, mse=9.43, rmse=3.07]\n",
      "Epoch: 100%|██████████| 2/2 [00:00<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for s1_io_flip_test with model units [[AtomicModelUnit(id='AttentionHead(Layer:7,Head:6,Token:all)'), AtomicModelUnit(id='AttentionHead(Layer:8,Head:1,Token:all)')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for s2_io_flip_test with model units [[AtomicModelUnit(id='AttentionHead(Layer:7,Head:6,Token:all)'), AtomicModelUnit(id='AttentionHead(Layer:8,Head:1,Token:all)')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  4.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for s1_ioi_flip_s2_ioi_flip_test with model units [[AtomicModelUnit(id='AttentionHead(Layer:7,Head:6,Token:all)'), AtomicModelUnit(id='AttentionHead(Layer:8,Head:1,Token:all)')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DAS training completed for output_position\n",
      "Models saved to: ioi_submission/ioi_task_Gemma2ForCausalLM_output_position\n"
     ]
    }
   ],
   "source": [
    "# Train DAS for output_position variable\n",
    "print(\"\\nTraining DAS for output_position variable...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Fix for in-place operation error during training\n",
    "# Set model to training mode and disable in-place operations\n",
    "pipeline.model.train()\n",
    "if hasattr(pipeline.model.config, 'use_cache'):\n",
    "    pipeline.model.config.use_cache = False\n",
    "\n",
    "target_variable = \"output_position\"\n",
    "position_model_dir = os.path.join(model_dir, f\"ioi_task_{pipeline.model.__class__.__name__}_{target_variable}\")\n",
    "\n",
    "attention_head_baselines(\n",
    "    pipeline=pipeline, \n",
    "    task=causal_model, \n",
    "    token_positions=token_positions, \n",
    "    train_data=train_data, \n",
    "    test_data=test_data, \n",
    "    config=config, \n",
    "    target_variables=[target_variable], \n",
    "    checker=lambda logits, params: checker(logits, params, pipeline), \n",
    "    verbose=True, \n",
    "    results_dir=results_dir,\n",
    "    model_dir=position_model_dir,\n",
    "    heads_list=heads_list,\n",
    "    skip=[\"full_vector\", \"DBM+SVD\", \"DBM+PCA\", \"DBM\", \"DBM+SAE\"]  # Only run DAS\n",
    ")\n",
    "\n",
    "print(f\"\\nDAS training completed for {target_variable}\")\n",
    "print(f\"Models saved to: {position_model_dir}\")\n",
    "\n",
    "# Clear memory\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train DAS on Output Token Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training DAS for output_token variable...\n",
      "============================================================\n",
      "Running DAS method...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0: 100%|██████████| 1/1 [00:00<00:00,  1.53it/s, loss=9.36, mse=9.36, rmse=3.06]\n",
      "Epoch: 1: 100%|██████████| 1/1 [00:00<00:00,  1.77it/s, loss=9.71, mse=9.72, rmse=3.12]\n",
      "Epoch: 100%|██████████| 2/2 [00:01<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for s1_io_flip_test with model units [[AtomicModelUnit(id='AttentionHead(Layer:7,Head:6,Token:all)'), AtomicModelUnit(id='AttentionHead(Layer:8,Head:1,Token:all)')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for s2_io_flip_test with model units [[AtomicModelUnit(id='AttentionHead(Layer:7,Head:6,Token:all)'), AtomicModelUnit(id='AttentionHead(Layer:8,Head:1,Token:all)')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  4.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running interventions for s1_ioi_flip_s2_ioi_flip_test with model units [[AtomicModelUnit(id='AttentionHead(Layer:7,Head:6,Token:all)'), AtomicModelUnit(id='AttentionHead(Layer:8,Head:1,Token:all)')]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00,  4.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DAS training completed for output_token\n",
      "Models saved to: ioi_submission/ioi_task_Gemma2ForCausalLM_output_token\n"
     ]
    }
   ],
   "source": [
    "# Train DAS for output_token variable\n",
    "print(\"\\nTraining DAS for output_token variable...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "target_variable = \"output_token\"\n",
    "token_model_dir = os.path.join(model_dir, f\"ioi_task_{pipeline.model.__class__.__name__}_{target_variable}\")\n",
    "\n",
    "# Increase feature dimension for output_token (it's predicting actual tokens, not just binary)\n",
    "config[\"n_features\"] = 64\n",
    "\n",
    "attention_head_baselines(\n",
    "    pipeline=pipeline, \n",
    "    task=causal_model, \n",
    "    token_positions=token_positions, \n",
    "    train_data=train_data, \n",
    "    test_data=test_data, \n",
    "    config=config, \n",
    "    target_variables=[target_variable], \n",
    "    checker=lambda logits, params: checker(logits, params, pipeline), \n",
    "    verbose=True, \n",
    "    results_dir=results_dir,\n",
    "    model_dir=token_model_dir,\n",
    "    heads_list=heads_list,\n",
    "    skip=[\"full_vector\", \"DBM+SVD\", \"DBM+PCA\", \"DBM\", \"DBM+SAE\"]  # Only run DAS\n",
    ")\n",
    "\n",
    "print(f\"\\nDAS training completed for {target_variable}\")\n",
    "print(f\"Models saved to: {token_model_dir}\")\n",
    "\n",
    "# Clear memory\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Save Linear Parameters for Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear parameters saved to: ioi_submission/ioi_linear_params.json\n",
      "{\n",
      "  \"gemma\": {\n",
      "    \"bias\": 11.7509765625,\n",
      "    \"token_coeff\": 0.0,\n",
      "    \"position_coeff\": -0.04589843749999991\n",
      "  },\n",
      "  \"model_class\": \"Gemma2ForCausalLM\",\n",
      "  \"heads_list\": [\n",
      "    [\n",
      "      7,\n",
      "      6\n",
      "    ],\n",
      "    [\n",
      "      8,\n",
      "      1\n",
      "    ]\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save the linear parameters we learned\n",
    "linear_params_file = os.path.join(model_dir, \"ioi_linear_params.json\")\n",
    "\n",
    "params_to_save = {\n",
    "    model_name: linear_params,\n",
    "    \"model_class\": pipeline.model.__class__.__name__,\n",
    "    \"heads_list\": heads_list\n",
    "}\n",
    "\n",
    "with open(linear_params_file, 'w') as f:\n",
    "    json.dump(params_to_save, f, indent=2)\n",
    "\n",
    "print(f\"Linear parameters saved to: {linear_params_file}\")\n",
    "print(json.dumps(params_to_save, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Verify Saved Models\n",
    "\n",
    "Let's verify that the models were saved correctly by listing the saved files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved model structure:\n",
      "\n",
      "ioi_submission/\n",
      "ioi_submission/\n",
      "  ioi_linear_params.json\n",
      "  ioi_task_Gemma2ForCausalLM_output_position/\n",
      "    AttentionHead(Layer:7,Head:6,Token:all)_featurizer\n",
      "    AttentionHead(Layer:7,Head:6,Token:all)_indices\n",
      "    AttentionHead(Layer:7,Head:6,Token:all)_inverse_featurizer\n",
      "    AttentionHead(Layer:8,Head:1,Token:all)_featurizer\n",
      "    AttentionHead(Layer:8,Head:1,Token:all)_indices\n",
      "    AttentionHead(Layer:8,Head:1,Token:all)_inverse_featurizer\n",
      "  ioi_task_Gemma2ForCausalLM_output_token/\n",
      "    AttentionHead(Layer:7,Head:6,Token:all)_featurizer\n",
      "    AttentionHead(Layer:7,Head:6,Token:all)_indices\n",
      "    AttentionHead(Layer:7,Head:6,Token:all)_inverse_featurizer\n",
      "    AttentionHead(Layer:8,Head:1,Token:all)_featurizer\n",
      "    AttentionHead(Layer:8,Head:1,Token:all)_indices\n",
      "    AttentionHead(Layer:8,Head:1,Token:all)_inverse_featurizer\n",
      "\n",
      "✓ Submission ready!\n",
      "\n",
      "Your submission folder 'ioi_submission' contains:\n",
      "- Trained DAS featurizers for both output_position and output_token\n",
      "- Linear parameters used for the causal model\n",
      "- All necessary files for evaluation\n"
     ]
    }
   ],
   "source": [
    "# List saved model files\n",
    "print(\"\\nSaved model structure:\")\n",
    "print(f\"\\n{model_dir}/\")\n",
    "\n",
    "for root, dirs, files in os.walk(model_dir):\n",
    "    level = root.replace(model_dir, '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in sorted(files)[:10]:  # Show first 10 files\n",
    "        print(f\"{subindent}{file}\")\n",
    "    if len(files) > 10:\n",
    "        print(f\"{subindent}... and {len(files) - 10} more files\")\n",
    "\n",
    "print(\"\\n✓ Submission ready!\")\n",
    "print(f\"\\nYour submission folder '{model_dir}' contains:\")\n",
    "print(\"- Trained DAS featurizers for both output_position and output_token\")\n",
    "print(\"- Linear parameters used for the causal model\")\n",
    "print(\"- All necessary files for evaluation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
